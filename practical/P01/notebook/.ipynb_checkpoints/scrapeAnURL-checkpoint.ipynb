{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biomolecular Interactions\n",
    "\n",
    "## Practical session P01 - Automatic retrieving data from the Web\n",
    "\n",
    "### Introduction\n",
    "\n",
    "When we deal with databases, it is always complicated to get your data nice and ready to be analyzed. This process is probably the most time-consuming step in [Data Science](https://en.wikipedia.org/wiki/Data_science). We want it to make it easier for you by teaching you a valuable technique called [Web Scraping](https://en.wikipedia.org/wiki/Web_scraping). It is the automated process of getting data from the internet to use later for your analytics. This task can endow your research with statistical significance and help you tackle many real-world problems you may deal with in your future professional careers; after all, the internet is all about data!\n",
    "\n",
    "In the Biomolecular Interactions course, we are dealing with how biology is arranged at the molecular level; how chemical interactions give rise to higher-level biological effects. These are not easy questions to answer but are profoundly fundamental if we want to understand the cell's physical basis. Many databases contain data about biochemical interactions and their chemical activities. We only use one to explain how to get the data; however, you can use the scraping knowledge gathered for almost any other website. \n",
    "\n",
    "In this practical session, we will scrape some simple data about the SARS-CoV-2's Spike protein. Exactly, how many structures there are for this protein, which regions they cover, resolution, and obtention method.\n",
    "\n",
    "We use the following URL:\n",
    "\n",
    "https://www.uniprot.org/uniprot/P0DTC2\n",
    "\n",
    "You need to fill in the details on how to retrieve this data from the given URL in the \"my_spiders.py\" file. Use \"Atom\" to edit that file. For every change made to that file, you need to:\n",
    "\n",
    "* Save the file from your editor\n",
    "\n",
    "$Ctrl+s$\n",
    "\n",
    "* Install the my_scrapy library from the terminal\n",
    "\n",
    "```python setup.py install```\n",
    "* Restart and re-run this notebook\n",
    "\n",
    "$Kernel -> Restart & Run All$\n",
    "\n",
    "We first import the library and then use myScrapingFunction to call the scraping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import my_scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_scrapy.myScrapingFunction('my_dictionary.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
